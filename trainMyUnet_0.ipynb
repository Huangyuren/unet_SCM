{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import  *\n",
    "from data import *\n",
    "from lr_reducer import *\n",
    "import os\n",
    "import keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using specified GPU\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_u_wi = 256\n",
    "input_u_he = 256\n",
    "train_path = \"data/train\"\n",
    "image_folder = \"image\"\n",
    "label_folder = \"label\"\n",
    "valid_path =  \"data/validation\"\n",
    "valid_image_folder =\"image\"\n",
    "valid_label_folder = \"label\"\n",
    "# log_filepath = './log'\n",
    "flag_multi_class = False\n",
    "num_classes = 2\n",
    "dp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n",
    "                         valid_path=valid_path,valid_image_folder=valid_image_folder,\n",
    "                         valid_label_folder=valid_label_folder,\n",
    "                         target_rows = input_u_wi, target_cols = input_u_he,\n",
    "                         flag_multi_class=flag_multi_class,\n",
    "                         num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yjhuang/keras_ted/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/yjhuang/keras_ted/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/yjhuang/keras_ted/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      "Found 35 images belonging to 1 classes.\n",
      "Found 350 images belonging to 1 classes.\n",
      "Found 35 images belonging to 1 classes.\n",
      "Found 350 images belonging to 1 classes.\n",
      "200/200 [==============================] - 87s 435ms/step - loss: 73.4820 - dice_coef: 0.8841 - val_loss: 34.8115 - val_dice_coef: 0.9276\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 34.81146, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00001: current best val_loss is: 34.81146\n",
      "\n",
      "Epoch 2/2000\n",
      "200/200 [==============================] - 79s 394ms/step - loss: 20.4838 - dice_coef: 0.9338 - val_loss: 11.2332 - val_dice_coef: 0.8985\n",
      "\n",
      "Epoch 00002: val_loss improved from 34.81146 to 11.23318, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00002: current best val_loss is: 11.23318\n",
      "\n",
      "Epoch 3/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 7.2567 - dice_coef: 0.9412 - val_loss: 4.5901 - val_dice_coef: 0.8995\n",
      "\n",
      "Epoch 00003: val_loss improved from 11.23318 to 4.59009, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00003: current best val_loss is: 4.59009\n",
      "\n",
      "Epoch 4/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 3.2405 - dice_coef: 0.9474 - val_loss: 2.3255 - val_dice_coef: 0.9116\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.59009 to 2.32555, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00004: current best val_loss is: 2.32555\n",
      "\n",
      "Epoch 5/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 1.7753 - dice_coef: 0.9522 - val_loss: 1.4226 - val_dice_coef: 0.9105\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.32555 to 1.42263, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00005: current best val_loss is: 1.42263\n",
      "\n",
      "Epoch 6/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 1.1533 - dice_coef: 0.9555 - val_loss: 1.0119 - val_dice_coef: 0.9038\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.42263 to 1.01194, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00006: current best val_loss is: 1.01194\n",
      "\n",
      "Epoch 7/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.8373 - dice_coef: 0.9599 - val_loss: 0.7909 - val_dice_coef: 0.9035\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01194 to 0.79088, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00007: current best val_loss is: 0.79088\n",
      "\n",
      "Epoch 8/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.6648 - dice_coef: 0.9625 - val_loss: 0.6574 - val_dice_coef: 0.9061\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.79088 to 0.65745, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00008: current best val_loss is: 0.65745\n",
      "\n",
      "Epoch 9/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.5526 - dice_coef: 0.9655 - val_loss: 0.5667 - val_dice_coef: 0.9064\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.65745 to 0.56668, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00009: current best val_loss is: 0.56668\n",
      "\n",
      "Epoch 10/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.4727 - dice_coef: 0.9678 - val_loss: 0.4925 - val_dice_coef: 0.9139\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.56668 to 0.49249, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00010: current best val_loss is: 0.49249\n",
      "\n",
      "Epoch 11/2000\n",
      "200/200 [==============================] - 79s 394ms/step - loss: 0.4091 - dice_coef: 0.9705 - val_loss: 0.4375 - val_dice_coef: 0.9146\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.49249 to 0.43745, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00011: current best val_loss is: 0.43745\n",
      "\n",
      "Epoch 12/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.3591 - dice_coef: 0.9719 - val_loss: 0.3799 - val_dice_coef: 0.9270\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.43745 to 0.37990, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00012: current best val_loss is: 0.37990\n",
      "\n",
      "Epoch 13/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.3144 - dice_coef: 0.9736 - val_loss: 0.3473 - val_dice_coef: 0.9197\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.37990 to 0.34726, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00013: current best val_loss is: 0.34726\n",
      "\n",
      "Epoch 14/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.2777 - dice_coef: 0.9750 - val_loss: 0.3162 - val_dice_coef: 0.9177\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34726 to 0.31620, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00014: current best val_loss is: 0.31620\n",
      "\n",
      "Epoch 15/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.2419 - dice_coef: 0.9760 - val_loss: 0.2743 - val_dice_coef: 0.9300\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.31620 to 0.27425, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00015: current best val_loss is: 0.27425\n",
      "\n",
      "Epoch 16/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.2116 - dice_coef: 0.9771 - val_loss: 0.2436 - val_dice_coef: 0.9300\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27425 to 0.24363, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00016: current best val_loss is: 0.24363\n",
      "\n",
      "Epoch 17/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.1872 - dice_coef: 0.9775 - val_loss: 0.2341 - val_dice_coef: 0.9155\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24363 to 0.23405, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00017: current best val_loss is: 0.23405\n",
      "\n",
      "Epoch 18/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.1622 - dice_coef: 0.9787 - val_loss: 0.2098 - val_dice_coef: 0.9183\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23405 to 0.20977, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00018: current best val_loss is: 0.20977\n",
      "\n",
      "Epoch 19/2000\n",
      "200/200 [==============================] - 79s 394ms/step - loss: 0.1391 - dice_coef: 0.9801 - val_loss: 0.1750 - val_dice_coef: 0.9339\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.20977 to 0.17497, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00019: current best val_loss is: 0.17497\n",
      "\n",
      "Epoch 20/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.1222 - dice_coef: 0.9801 - val_loss: 0.1671 - val_dice_coef: 0.9252\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.17497 to 0.16715, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00020: current best val_loss is: 0.16715\n",
      "\n",
      "Epoch 21/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.1053 - dice_coef: 0.9811 - val_loss: 0.1432 - val_dice_coef: 0.9345\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.16715 to 0.14325, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00021: current best val_loss is: 0.14325\n",
      "\n",
      "Epoch 22/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0931 - dice_coef: 0.9800 - val_loss: 0.1208 - val_dice_coef: 0.9461\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.14325 to 0.12080, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00022: current best val_loss is: 0.12080\n",
      "\n",
      "Epoch 23/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0801 - dice_coef: 0.9815 - val_loss: 0.1258 - val_dice_coef: 0.9291\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.12080\n",
      "Epoch 24/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0743 - dice_coef: 0.9816 - val_loss: 0.1342 - val_dice_coef: 0.9123\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.12080\n",
      "Epoch 25/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0608 - dice_coef: 0.9824 - val_loss: 0.1216 - val_dice_coef: 0.9167\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.12080\n",
      "Epoch 26/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0528 - dice_coef: 0.9828 - val_loss: 0.1019 - val_dice_coef: 0.9293\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.12080 to 0.10191, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00026: current best val_loss is: 0.10191\n",
      "\n",
      "Epoch 27/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0461 - dice_coef: 0.9833 - val_loss: 0.1021 - val_dice_coef: 0.9233\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.10191\n",
      "Epoch 28/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0435 - dice_coef: 0.9827 - val_loss: 0.1086 - val_dice_coef: 0.9130\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.10191\n",
      "Epoch 29/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0403 - dice_coef: 0.9820 - val_loss: 0.1045 - val_dice_coef: 0.9141\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.10191\n",
      "Epoch 30/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0357 - dice_coef: 0.9828 - val_loss: 0.0995 - val_dice_coef: 0.9154\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.10191 to 0.09950, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00030: current best val_loss is: 0.09950\n",
      "\n",
      "Epoch 31/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0305 - dice_coef: 0.9841 - val_loss: 0.0880 - val_dice_coef: 0.9239\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.09950 to 0.08798, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00031: current best val_loss is: 0.08798\n",
      "\n",
      "Epoch 32/2000\n",
      "200/200 [==============================] - 79s 393ms/step - loss: 0.0306 - dice_coef: 0.9824 - val_loss: 0.0821 - val_dice_coef: 0.9281\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.08798 to 0.08215, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00032: current best val_loss is: 0.08215\n",
      "\n",
      "Epoch 33/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0254 - dice_coef: 0.9844 - val_loss: 0.0664 - val_dice_coef: 0.9417\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.08215 to 0.06638, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00033: current best val_loss is: 0.06638\n",
      "\n",
      "Epoch 34/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0258 - dice_coef: 0.9828 - val_loss: 0.0674 - val_dice_coef: 0.9395\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.06638\n",
      "Epoch 35/2000\n",
      "200/200 [==============================] - 79s 393ms/step - loss: 0.0291 - dice_coef: 0.9814 - val_loss: 0.0974 - val_dice_coef: 0.9094\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.06638\n",
      "Epoch 36/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0240 - dice_coef: 0.9835 - val_loss: 0.0973 - val_dice_coef: 0.9082\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.06638\n",
      "Epoch 37/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0234 - dice_coef: 0.9840 - val_loss: 0.0879 - val_dice_coef: 0.9173\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.06638\n",
      "Epoch 38/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0213 - dice_coef: 0.9842 - val_loss: 0.0500 - val_dice_coef: 0.9543\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.06638 to 0.04998, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00038: current best val_loss is: 0.04998\n",
      "\n",
      "Epoch 39/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0200 - dice_coef: 0.9848 - val_loss: 0.0703 - val_dice_coef: 0.9334\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04998\n",
      "Epoch 40/2000\n",
      "200/200 [==============================] - 80s 399ms/step - loss: 0.0225 - dice_coef: 0.9832 - val_loss: 0.0750 - val_dice_coef: 0.9290\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04998\n",
      "Epoch 41/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0213 - dice_coef: 0.9841 - val_loss: 0.0760 - val_dice_coef: 0.9277\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04998\n",
      "Epoch 42/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0217 - dice_coef: 0.9836 - val_loss: 0.0714 - val_dice_coef: 0.9324\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04998\n",
      "Epoch 43/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0199 - dice_coef: 0.9842 - val_loss: 0.0539 - val_dice_coef: 0.9493\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04998\n",
      "Epoch 44/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0206 - dice_coef: 0.9838 - val_loss: 0.0538 - val_dice_coef: 0.9493\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04998\n",
      "Epoch 45/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0208 - dice_coef: 0.9845 - val_loss: 0.0687 - val_dice_coef: 0.9347\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04998\n",
      "Epoch 46/2000\n",
      "200/200 [==============================] - 78s 392ms/step - loss: 0.0202 - dice_coef: 0.9843 - val_loss: 0.0551 - val_dice_coef: 0.9481\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04998\n",
      "Epoch 47/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0224 - dice_coef: 0.9836 - val_loss: 0.0686 - val_dice_coef: 0.9353\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04998\n",
      "Epoch 48/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0206 - dice_coef: 0.9843 - val_loss: 0.0668 - val_dice_coef: 0.9365\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04998\n",
      "Epoch 49/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0209 - dice_coef: 0.9840 - val_loss: 0.0499 - val_dice_coef: 0.9535\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.04998 to 0.04994, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00049: current best val_loss is: 0.04994\n",
      "\n",
      "Epoch 50/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0214 - dice_coef: 0.9830 - val_loss: 0.0836 - val_dice_coef: 0.9195\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04994\n",
      "Epoch 51/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0181 - dice_coef: 0.9855 - val_loss: 0.0523 - val_dice_coef: 0.9505\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.04994\n",
      "Epoch 52/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0214 - dice_coef: 0.9844 - val_loss: 0.0541 - val_dice_coef: 0.9494\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.04994\n",
      "Epoch 53/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0209 - dice_coef: 0.9829 - val_loss: 0.0619 - val_dice_coef: 0.9409\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04994\n",
      "Epoch 54/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0206 - dice_coef: 0.9832 - val_loss: 0.0544 - val_dice_coef: 0.9484\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04994\n",
      "Epoch 55/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0190 - dice_coef: 0.9848 - val_loss: 0.0481 - val_dice_coef: 0.9546\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.04994 to 0.04815, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00055: current best val_loss is: 0.04815\n",
      "\n",
      "Epoch 56/2000\n",
      "200/200 [==============================] - 79s 393ms/step - loss: 0.0193 - dice_coef: 0.9845 - val_loss: 0.0454 - val_dice_coef: 0.9572\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.04815 to 0.04545, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00056: current best val_loss is: 0.04545\n",
      "\n",
      "Epoch 57/2000\n",
      "200/200 [==============================] - 80s 399ms/step - loss: 0.0197 - dice_coef: 0.9846 - val_loss: 0.0472 - val_dice_coef: 0.9557\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04545\n",
      "Epoch 58/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0197 - dice_coef: 0.9838 - val_loss: 0.0675 - val_dice_coef: 0.9351\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.04545\n",
      "Epoch 59/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0210 - dice_coef: 0.9835 - val_loss: 0.0524 - val_dice_coef: 0.9505\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.04545\n",
      "Epoch 60/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0188 - dice_coef: 0.9843 - val_loss: 0.0527 - val_dice_coef: 0.9497\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.04545\n",
      "Epoch 61/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0199 - dice_coef: 0.9835 - val_loss: 0.0473 - val_dice_coef: 0.9551\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.04545\n",
      "Epoch 62/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0201 - dice_coef: 0.9835 - val_loss: 0.0561 - val_dice_coef: 0.9465\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.04545\n",
      "Epoch 63/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0216 - dice_coef: 0.9837 - val_loss: 0.0649 - val_dice_coef: 0.9381\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.04545\n",
      "Epoch 64/2000\n",
      "200/200 [==============================] - 79s 394ms/step - loss: 0.0193 - dice_coef: 0.9845 - val_loss: 0.0628 - val_dice_coef: 0.9399\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.04545\n",
      "Epoch 65/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0222 - dice_coef: 0.9823 - val_loss: 0.0706 - val_dice_coef: 0.9322\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.04545\n",
      "Epoch 66/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0212 - dice_coef: 0.9834 - val_loss: 0.0832 - val_dice_coef: 0.9197\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.04545\n",
      "Epoch 67/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0192 - dice_coef: 0.9840 - val_loss: 0.0488 - val_dice_coef: 0.9537\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.04545\n",
      "Epoch 68/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0200 - dice_coef: 0.9837 - val_loss: 0.0470 - val_dice_coef: 0.9557\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.04545\n",
      "Epoch 69/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0180 - dice_coef: 0.9852 - val_loss: 0.0550 - val_dice_coef: 0.9474\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.04545\n",
      "Epoch 70/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0187 - dice_coef: 0.9845 - val_loss: 0.0564 - val_dice_coef: 0.9458\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.04545\n",
      "Epoch 71/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0182 - dice_coef: 0.9847 - val_loss: 0.0481 - val_dice_coef: 0.9541\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.04545\n",
      "Epoch 72/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0192 - dice_coef: 0.9841 - val_loss: 0.0525 - val_dice_coef: 0.9498\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.04545\n",
      "Epoch 73/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0332 - dice_coef: 0.9714 - val_loss: 0.0502 - val_dice_coef: 0.9532\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.04545\n",
      "Epoch 74/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0226 - dice_coef: 0.9812 - val_loss: 0.0547 - val_dice_coef: 0.9481\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.04545\n",
      "Epoch 75/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0214 - dice_coef: 0.9826 - val_loss: 0.0537 - val_dice_coef: 0.9490\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.04545\n",
      "Epoch 76/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0193 - dice_coef: 0.9841 - val_loss: 0.0456 - val_dice_coef: 0.9569\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.04545\n",
      "Epoch 77/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0228 - dice_coef: 0.9807 - val_loss: 0.0458 - val_dice_coef: 0.9566\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.04545\n",
      "Epoch 00077: LrReducer reduce learning rate to 1.9999999494757503e-05.\n",
      "\n",
      "Epoch 78/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0183 - dice_coef: 0.9843 - val_loss: 0.0425 - val_dice_coef: 0.9599\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.04545 to 0.04246, saving model to models_SCM_muscle/unet_SCM_31.hdf5\n",
      "Epoch 00078: current best val_loss is: 0.04246\n",
      "\n",
      "Epoch 79/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0178 - dice_coef: 0.9846 - val_loss: 0.0436 - val_dice_coef: 0.9586\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.04246\n",
      "Epoch 80/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0183 - dice_coef: 0.9841 - val_loss: 0.0427 - val_dice_coef: 0.9596\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04246\n",
      "Epoch 81/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0175 - dice_coef: 0.9848 - val_loss: 0.0447 - val_dice_coef: 0.9575\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04246\n",
      "Epoch 82/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0176 - dice_coef: 0.9845 - val_loss: 0.0448 - val_dice_coef: 0.9573\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04246\n",
      "Epoch 83/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0177 - dice_coef: 0.9845 - val_loss: 0.0453 - val_dice_coef: 0.9568\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04246\n",
      "Epoch 84/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0168 - dice_coef: 0.9853 - val_loss: 0.0448 - val_dice_coef: 0.9572\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04246\n",
      "Epoch 85/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0170 - dice_coef: 0.9850 - val_loss: 0.0456 - val_dice_coef: 0.9563\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04246\n",
      "Epoch 86/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0172 - dice_coef: 0.9847 - val_loss: 0.0459 - val_dice_coef: 0.9559\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04246\n",
      "Epoch 87/2000\n",
      "200/200 [==============================] - 80s 399ms/step - loss: 0.0183 - dice_coef: 0.9838 - val_loss: 0.0444 - val_dice_coef: 0.9575\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04246\n",
      "Epoch 88/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0178 - dice_coef: 0.9843 - val_loss: 0.0456 - val_dice_coef: 0.9563\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04246\n",
      "Epoch 89/2000\n",
      "200/200 [==============================] - 80s 399ms/step - loss: 0.0170 - dice_coef: 0.9849 - val_loss: 0.0458 - val_dice_coef: 0.9560\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04246\n",
      "Epoch 90/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0167 - dice_coef: 0.9851 - val_loss: 0.0474 - val_dice_coef: 0.9543\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.04246\n",
      "Epoch 91/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0164 - dice_coef: 0.9853 - val_loss: 0.0462 - val_dice_coef: 0.9555\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04246\n",
      "Epoch 92/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0171 - dice_coef: 0.9847 - val_loss: 0.0426 - val_dice_coef: 0.9592\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04246\n",
      "Epoch 93/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0159 - dice_coef: 0.9858 - val_loss: 0.0456 - val_dice_coef: 0.9561\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.04246\n",
      "Epoch 94/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0165 - dice_coef: 0.9852 - val_loss: 0.0454 - val_dice_coef: 0.9563\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04246\n",
      "Epoch 95/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0167 - dice_coef: 0.9851 - val_loss: 0.0443 - val_dice_coef: 0.9574\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04246\n",
      "Epoch 96/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0158 - dice_coef: 0.9859 - val_loss: 0.0455 - val_dice_coef: 0.9562\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04246\n",
      "Epoch 97/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0167 - dice_coef: 0.9849 - val_loss: 0.0476 - val_dice_coef: 0.9540\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04246\n",
      "Epoch 98/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0166 - dice_coef: 0.9850 - val_loss: 0.0459 - val_dice_coef: 0.9557\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04246\n",
      "Epoch 99/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0154 - dice_coef: 0.9862 - val_loss: 0.0476 - val_dice_coef: 0.9540\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04246\n",
      "Epoch 00099: LrReducer reduce learning rate to 3.999999898951501e-06.\n",
      "\n",
      "Epoch 100/2000\n",
      "200/200 [==============================] - 80s 399ms/step - loss: 0.0161 - dice_coef: 0.9855 - val_loss: 0.0476 - val_dice_coef: 0.9539\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04246\n",
      "Epoch 101/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0159 - dice_coef: 0.9856 - val_loss: 0.0446 - val_dice_coef: 0.9570\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04246\n",
      "Epoch 102/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0158 - dice_coef: 0.9858 - val_loss: 0.0430 - val_dice_coef: 0.9585\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04246\n",
      "Epoch 103/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0160 - dice_coef: 0.9856 - val_loss: 0.0465 - val_dice_coef: 0.9551\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04246\n",
      "Epoch 104/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0157 - dice_coef: 0.9858 - val_loss: 0.0443 - val_dice_coef: 0.9572\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04246\n",
      "Epoch 105/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0158 - dice_coef: 0.9857 - val_loss: 0.0461 - val_dice_coef: 0.9554\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04246\n",
      "Epoch 106/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0154 - dice_coef: 0.9861 - val_loss: 0.0459 - val_dice_coef: 0.9556\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04246\n",
      "Epoch 107/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0155 - dice_coef: 0.9860 - val_loss: 0.0446 - val_dice_coef: 0.9569\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04246\n",
      "Epoch 108/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0155 - dice_coef: 0.9860 - val_loss: 0.0464 - val_dice_coef: 0.9551\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04246\n",
      "Epoch 109/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0160 - dice_coef: 0.9855 - val_loss: 0.0459 - val_dice_coef: 0.9556\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04246\n",
      "Epoch 110/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0159 - dice_coef: 0.9856 - val_loss: 0.0460 - val_dice_coef: 0.9555\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04246\n",
      "Epoch 111/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0153 - dice_coef: 0.9862 - val_loss: 0.0452 - val_dice_coef: 0.9562\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.04246\n",
      "Epoch 112/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0156 - dice_coef: 0.9859 - val_loss: 0.0452 - val_dice_coef: 0.9562\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04246\n",
      "Epoch 113/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0156 - dice_coef: 0.9858 - val_loss: 0.0459 - val_dice_coef: 0.9556\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04246\n",
      "Epoch 114/2000\n",
      "200/200 [==============================] - 79s 393ms/step - loss: 0.0153 - dice_coef: 0.9861 - val_loss: 0.0466 - val_dice_coef: 0.9548\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.04246\n",
      "Epoch 115/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0153 - dice_coef: 0.9862 - val_loss: 0.0435 - val_dice_coef: 0.9580\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.04246\n",
      "Epoch 116/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0157 - dice_coef: 0.9857 - val_loss: 0.0452 - val_dice_coef: 0.9563\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.04246\n",
      "Epoch 117/2000\n",
      "200/200 [==============================] - 79s 394ms/step - loss: 0.0153 - dice_coef: 0.9862 - val_loss: 0.0445 - val_dice_coef: 0.9570\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.04246\n",
      "Epoch 118/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0154 - dice_coef: 0.9860 - val_loss: 0.0457 - val_dice_coef: 0.9558\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.04246\n",
      "Epoch 119/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0152 - dice_coef: 0.9863 - val_loss: 0.0453 - val_dice_coef: 0.9562\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.04246\n",
      "Epoch 120/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0156 - dice_coef: 0.9858 - val_loss: 0.0456 - val_dice_coef: 0.9558\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.04246\n",
      "Epoch 00120: LrReducer reduce learning rate to 7.999999979801942e-07.\n",
      "\n",
      "Epoch 121/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0154 - dice_coef: 0.9860 - val_loss: 0.0450 - val_dice_coef: 0.9564\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.04246\n",
      "Epoch 122/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0155 - dice_coef: 0.9859 - val_loss: 0.0447 - val_dice_coef: 0.9567\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.04246\n",
      "Epoch 123/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0149 - dice_coef: 0.9866 - val_loss: 0.0457 - val_dice_coef: 0.9557\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.04246\n",
      "Epoch 124/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0154 - dice_coef: 0.9860 - val_loss: 0.0450 - val_dice_coef: 0.9564\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.04246\n",
      "Epoch 125/2000\n",
      "200/200 [==============================] - 79s 394ms/step - loss: 0.0148 - dice_coef: 0.9866 - val_loss: 0.0466 - val_dice_coef: 0.9549\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.04246\n",
      "Epoch 126/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0147 - dice_coef: 0.9867 - val_loss: 0.0460 - val_dice_coef: 0.9554\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.04246\n",
      "Epoch 127/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0152 - dice_coef: 0.9862 - val_loss: 0.0473 - val_dice_coef: 0.9541\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.04246\n",
      "Epoch 128/2000\n",
      "200/200 [==============================] - 79s 394ms/step - loss: 0.0154 - dice_coef: 0.9860 - val_loss: 0.0465 - val_dice_coef: 0.9549\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04246\n",
      "Epoch 129/2000\n",
      "200/200 [==============================] - 79s 394ms/step - loss: 0.0154 - dice_coef: 0.9860 - val_loss: 0.0464 - val_dice_coef: 0.9550\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.04246\n",
      "Epoch 130/2000\n",
      "200/200 [==============================] - 79s 393ms/step - loss: 0.0152 - dice_coef: 0.9862 - val_loss: 0.0446 - val_dice_coef: 0.9568\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.04246\n",
      "Epoch 131/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0153 - dice_coef: 0.9861 - val_loss: 0.0455 - val_dice_coef: 0.9559\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.04246\n",
      "Epoch 132/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0153 - dice_coef: 0.9862 - val_loss: 0.0446 - val_dice_coef: 0.9568\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.04246\n",
      "Epoch 133/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0155 - dice_coef: 0.9860 - val_loss: 0.0480 - val_dice_coef: 0.9534\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.04246\n",
      "Epoch 134/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0150 - dice_coef: 0.9864 - val_loss: 0.0443 - val_dice_coef: 0.9571\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.04246\n",
      "Epoch 135/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0155 - dice_coef: 0.9859 - val_loss: 0.0448 - val_dice_coef: 0.9566\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.04246\n",
      "Epoch 136/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0148 - dice_coef: 0.9866 - val_loss: 0.0436 - val_dice_coef: 0.9578\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04246\n",
      "Epoch 137/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0150 - dice_coef: 0.9864 - val_loss: 0.0441 - val_dice_coef: 0.9573\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.04246\n",
      "Epoch 138/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0158 - dice_coef: 0.9856 - val_loss: 0.0450 - val_dice_coef: 0.9564\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04246\n",
      "Epoch 139/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0151 - dice_coef: 0.9863 - val_loss: 0.0470 - val_dice_coef: 0.9544\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.04246\n",
      "Epoch 140/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 79s 394ms/step - loss: 0.0149 - dice_coef: 0.9865 - val_loss: 0.0440 - val_dice_coef: 0.9574\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04246\n",
      "Epoch 141/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0151 - dice_coef: 0.9863 - val_loss: 0.0435 - val_dice_coef: 0.9579\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04246\n",
      "Epoch 00141: LrReducer reduce learning rate to 1.600000018697756e-07.\n",
      "\n",
      "Epoch 142/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0152 - dice_coef: 0.9862 - val_loss: 0.0464 - val_dice_coef: 0.9550\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.04246\n",
      "Epoch 143/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0149 - dice_coef: 0.9865 - val_loss: 0.0440 - val_dice_coef: 0.9574\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.04246\n",
      "Epoch 144/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0147 - dice_coef: 0.9867 - val_loss: 0.0429 - val_dice_coef: 0.9585\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.04246\n",
      "Epoch 145/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0149 - dice_coef: 0.9865 - val_loss: 0.0469 - val_dice_coef: 0.9545\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.04246\n",
      "Epoch 146/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0147 - dice_coef: 0.9868 - val_loss: 0.0445 - val_dice_coef: 0.9570\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.04246\n",
      "Epoch 147/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0147 - dice_coef: 0.9867 - val_loss: 0.0450 - val_dice_coef: 0.9564\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.04246\n",
      "Epoch 148/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0152 - dice_coef: 0.9862 - val_loss: 0.0453 - val_dice_coef: 0.9561\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.04246\n",
      "Epoch 149/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0150 - dice_coef: 0.9865 - val_loss: 0.0459 - val_dice_coef: 0.9555\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.04246\n",
      "Epoch 150/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0150 - dice_coef: 0.9864 - val_loss: 0.0429 - val_dice_coef: 0.9585\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.04246\n",
      "Epoch 151/2000\n",
      "200/200 [==============================] - 79s 394ms/step - loss: 0.0154 - dice_coef: 0.9860 - val_loss: 0.0463 - val_dice_coef: 0.9551\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.04246\n",
      "Epoch 152/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0153 - dice_coef: 0.9861 - val_loss: 0.0452 - val_dice_coef: 0.9562\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.04246\n",
      "Epoch 153/2000\n",
      "200/200 [==============================] - 79s 395ms/step - loss: 0.0155 - dice_coef: 0.9859 - val_loss: 0.0441 - val_dice_coef: 0.9573\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.04246\n",
      "Epoch 154/2000\n",
      "200/200 [==============================] - 79s 397ms/step - loss: 0.0155 - dice_coef: 0.9859 - val_loss: 0.0448 - val_dice_coef: 0.9566\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.04246\n",
      "Epoch 155/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0149 - dice_coef: 0.9865 - val_loss: 0.0464 - val_dice_coef: 0.9550\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.04246\n",
      "Epoch 156/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0153 - dice_coef: 0.9861 - val_loss: 0.0434 - val_dice_coef: 0.9580\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.04246\n",
      "Epoch 157/2000\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 0.0147 - dice_coef: 0.9867 - val_loss: 0.0425 - val_dice_coef: 0.9589\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.04246\n",
      "Epoch 158/2000\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 0.0147 - dice_coef: 0.9867 - val_loss: 0.0459 - val_dice_coef: 0.9555\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.04246\n",
      "Epoch 00158: early stopping\n",
      "training time amount: 12566.296716451645\n"
     ]
    }
   ],
   "source": [
    "train_data = dp.trainGenerator(batch_size=10)\n",
    "valid_data = dp.validation_load(batch_size=10)\n",
    "model = unet_v1(input_size = (input_u_wi, input_u_he, 3))\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=40)\n",
    "csv_logger = CSVLogger('csvLogger/training_28.log', separator=',', append=False)\n",
    "tbcallback = TensorBoard(log_dir='./tensorboard/Graph_0', histogram_freq=0, batch_size=10, write_graph=True, write_grads=True, write_images=True, \n",
    "                         embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "reduce_lr = LrReducer(monitor='val_loss', patience=20, reduce_rate=0.2,  verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('models_SCM_muscle/unet_SCM_28.hdf5', monitor='val_loss',verbose=1, save_best_only=True)\n",
    "start = time.time()\n",
    "his = model.fit_generator(train_data, steps_per_epoch=200,\n",
    "                    validation_data=valid_data, validation_steps=100,\n",
    "                   epochs = 2000, callbacks=[model_checkpoint, tbcallback, reduce_lr, csv_logger, es])     \n",
    "end = time.time()\n",
    "print('training time amount: '+str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "plt.figure()\n",
    "plt.plot(his.history['loss'], label='loss')\n",
    "plt.plot(his.history['val_loss'], label='val_loss')\n",
    "plt.plot(his.history['dice_coef'], label='dice_coef')\n",
    "plt.plot(his.history['val_dice_coef'], label='val_dice_coef')\n",
    "plt.title(\"Training Loss & Dice on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"result_plots/scm_plots/plot_scm_28.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
